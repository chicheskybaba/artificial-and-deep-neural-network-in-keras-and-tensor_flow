{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf010558-7354-4f8d-b33a-b5d2ff761628",
   "metadata": {},
   "source": [
    "# Dataset import and exploration\n",
    "- https://www.kaggle.com/shelvigarg/wine-quality-dataset\n",
    "- Refer to https://github.com/better-data-science/TensorFlow/blob/main/003_TensorFlow_Classification.ipynb for detailed preparation instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca51a1b1-bba1-4832-b177-e0be1f3aee9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>white</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.45</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.054</td>\n",
       "      <td>56.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.47</td>\n",
       "      <td>10.00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4416</th>\n",
       "      <td>white</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.47</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.069</td>\n",
       "      <td>35.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>0.99391</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.75</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4866</th>\n",
       "      <td>white</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.048</td>\n",
       "      <td>30.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.99138</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.55</td>\n",
       "      <td>11.20</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4338</th>\n",
       "      <td>white</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.27</td>\n",
       "      <td>13.9</td>\n",
       "      <td>0.057</td>\n",
       "      <td>45.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>0.99807</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.41</td>\n",
       "      <td>8.80</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5244</th>\n",
       "      <td>red</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.072</td>\n",
       "      <td>17.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99550</td>\n",
       "      <td>3.58</td>\n",
       "      <td>0.89</td>\n",
       "      <td>12.30</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       type  fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "349   white            7.6             0.170         0.45            11.2   \n",
       "4416  white            5.7             0.240         0.47             6.3   \n",
       "4866  white            5.7             0.410         0.21             1.9   \n",
       "4338  white            7.3             0.190         0.27            13.9   \n",
       "5244    red            6.6             0.815         0.02             2.7   \n",
       "\n",
       "      chlorides  free sulfur dioxide  total sulfur dioxide  density    pH  \\\n",
       "349       0.054                 56.0                 137.0  0.99700  3.15   \n",
       "4416      0.069                 35.0                 182.0  0.99391  3.11   \n",
       "4866      0.048                 30.0                 112.0  0.99138  3.29   \n",
       "4338      0.057                 45.0                 155.0  0.99807  2.94   \n",
       "5244      0.072                 17.0                  34.0  0.99550  3.58   \n",
       "\n",
       "      sulphates  alcohol  quality  \n",
       "349        0.47    10.00        5  \n",
       "4416       0.46     9.75        5  \n",
       "4866       0.55    11.20        6  \n",
       "4338       0.41     8.80        8  \n",
       "5244       0.89    12.30        7  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('data/winequalityN.csv')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f8ccfbf-d0f9-4128-ab3b-d6ab1489f205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Prepare the data\n",
    "df = df.dropna()\n",
    "df['is_white_wine'] = [1 if typ == 'white' else 0 for typ in df['type']]\n",
    "df['is_good_wine'] = [1 if quality >= 6 else 0 for quality in df['quality']]\n",
    "df.drop(['type', 'quality'], axis=1, inplace=True)\n",
    "\n",
    "# Train/test split\n",
    "X = df.drop('is_good_wine', axis=1)\n",
    "y = df['is_good_wine']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e70cb7-d3e7-49b0-aeb7-aa2a3ca19a41",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e42d1f6-1c30-4334-8397-b8772f958979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bed9be-de94-4a6f-bb1d-5fd571f697a4",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Callbacks list\n",
    "- I like to declare it beforehand\n",
    "\n",
    "### `ModelCheckpoint`\n",
    "- It will save the model locally on the current epoch if it beats the performance on the previous one\n",
    "- The configuration below saves it to a `hdf5` file in the following format:\n",
    "    - `<dir>/model-<epoch>-<accuracy>.hdf5`\n",
    "- Model is saved only if the validation accuracy is higher than on the previous epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae4dc04b-530f-4320-831e-d31b311f69dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='checkpoints/model-{epoch:02d}-{val_accuracy:.2f}.hdf5',\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7509f244-b817-44ba-9221-44606ac21d4f",
   "metadata": {},
   "source": [
    "### `ReduceLROnPlateau`\n",
    "- Basically if a metric (validation loss) doesn't decrease for a number of epochs (10), reduce the learning rate\n",
    "- New learning rate = old learning rate * factor (0.1)\n",
    "    - nlr = 0.01 * 0.1 = 0.001\n",
    "- You can also set the minimum learning rate below the model won't go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be8e7d24-ea3a-48a1-8deb-8373b1978213",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_reducelr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    factor=0.1,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    min_lr=0.00001\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe6748b-df60-4a4e-b3cc-9e51f0ed66b7",
   "metadata": {},
   "source": [
    "### `EarlyStopping`\n",
    "- If a metric (validation accuracy) doesn't increase by some minimum delta (0.001) for a given number of epochs (10) - kill the training process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c438c4ed-34e7-4ba0-8564-20601d46f80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_earlystop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    min_delta=0.001,\n",
    "    patience=10,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b94763b-b620-4aac-9475-5925d87b87a5",
   "metadata": {},
   "source": [
    "### `CSVLogger`\n",
    "- Captures model training history and dumps it to a CSV file\n",
    "- Useful for analyzing the performance later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a82de6e-fa77-4701-a18f-82e0bd403f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_csvlogger = tf.keras.callbacks.CSVLogger(\n",
    "    filename='training_log.csv',\n",
    "    separator=',',\n",
    "    append=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa112e1-97f3-4e81-a598-d7f45795d769",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- For simplicity's sake we'll treat test set as a validation set\n",
    "- In real deep learning projects you'll want to have 3 sets: training, validation, and test\n",
    "- We'll tell the model to train for 1000 epochs, but the `EarlyStopping` callback will kill it way before\n",
    "- Specify callbacks in the `fit()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b611c9b-7da2-4b16-9161-272bf69abecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "162/162 [==============================] - ETA: 0s - loss: 0.5370 - accuracy: 0.7251\n",
      "Epoch 1: val_accuracy improved from -inf to 0.76102, saving model to checkpoints\\model-01-0.76.hdf5\n",
      "162/162 [==============================] - 16s 17ms/step - loss: 0.5370 - accuracy: 0.7251 - val_loss: 0.4970 - val_accuracy: 0.7610 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "153/162 [===========================>..] - ETA: 0s - loss: 0.4944 - accuracy: 0.7651\n",
      "Epoch 2: val_accuracy did not improve from 0.76102\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.4945 - accuracy: 0.7652 - val_loss: 0.5033 - val_accuracy: 0.7587 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "156/162 [===========================>..] - ETA: 0s - loss: 0.4827 - accuracy: 0.7704\n",
      "Epoch 3: val_accuracy improved from 0.76102 to 0.76566, saving model to checkpoints\\model-03-0.77.hdf5\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.4832 - accuracy: 0.7708 - val_loss: 0.4741 - val_accuracy: 0.7657 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "148/162 [==========================>...] - ETA: 0s - loss: 0.4694 - accuracy: 0.7821\n",
      "Epoch 4: val_accuracy did not improve from 0.76566\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.4695 - accuracy: 0.7814 - val_loss: 0.4836 - val_accuracy: 0.7602 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "148/162 [==========================>...] - ETA: 0s - loss: 0.4633 - accuracy: 0.7793\n",
      "Epoch 5: val_accuracy improved from 0.76566 to 0.77108, saving model to checkpoints\\model-05-0.77.hdf5\n",
      "162/162 [==============================] - 1s 7ms/step - loss: 0.4648 - accuracy: 0.7787 - val_loss: 0.4736 - val_accuracy: 0.7711 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "157/162 [============================>.] - ETA: 0s - loss: 0.4565 - accuracy: 0.7858\n",
      "Epoch 6: val_accuracy improved from 0.77108 to 0.77185, saving model to checkpoints\\model-06-0.77.hdf5\n",
      "162/162 [==============================] - 2s 10ms/step - loss: 0.4561 - accuracy: 0.7867 - val_loss: 0.4684 - val_accuracy: 0.7718 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "153/162 [===========================>..] - ETA: 0s - loss: 0.4508 - accuracy: 0.7841\n",
      "Epoch 7: val_accuracy improved from 0.77185 to 0.77572, saving model to checkpoints\\model-07-0.78.hdf5\n",
      "162/162 [==============================] - 2s 12ms/step - loss: 0.4509 - accuracy: 0.7834 - val_loss: 0.4706 - val_accuracy: 0.7757 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "142/162 [=========================>....] - ETA: 0s - loss: 0.4414 - accuracy: 0.7914\n",
      "Epoch 8: val_accuracy did not improve from 0.77572\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.4437 - accuracy: 0.7890 - val_loss: 0.4685 - val_accuracy: 0.7633 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "156/162 [===========================>..] - ETA: 0s - loss: 0.4352 - accuracy: 0.7955\n",
      "Epoch 9: val_accuracy did not improve from 0.77572\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7948 - val_loss: 0.4680 - val_accuracy: 0.7680 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "156/162 [===========================>..] - ETA: 0s - loss: 0.4331 - accuracy: 0.7973\n",
      "Epoch 10: val_accuracy did not improve from 0.77572\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7975 - val_loss: 0.4751 - val_accuracy: 0.7718 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "146/162 [==========================>...] - ETA: 0s - loss: 0.4251 - accuracy: 0.8024\n",
      "Epoch 11: val_accuracy did not improve from 0.77572\n",
      "162/162 [==============================] - 2s 13ms/step - loss: 0.4267 - accuracy: 0.8002 - val_loss: 0.4762 - val_accuracy: 0.7680 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "156/162 [===========================>..] - ETA: 0s - loss: 0.4205 - accuracy: 0.8081\n",
      "Epoch 12: val_accuracy improved from 0.77572 to 0.77881, saving model to checkpoints\\model-12-0.78.hdf5\n",
      "162/162 [==============================] - 2s 11ms/step - loss: 0.4210 - accuracy: 0.8072 - val_loss: 0.4726 - val_accuracy: 0.7788 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "155/162 [===========================>..] - ETA: 0s - loss: 0.4186 - accuracy: 0.7990\n",
      "Epoch 13: val_accuracy did not improve from 0.77881\n",
      "162/162 [==============================] - 2s 13ms/step - loss: 0.4155 - accuracy: 0.8004 - val_loss: 0.4910 - val_accuracy: 0.7680 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "161/162 [============================>.] - ETA: 0s - loss: 0.4120 - accuracy: 0.8090\n",
      "Epoch 14: val_accuracy did not improve from 0.77881\n",
      "162/162 [==============================] - 2s 10ms/step - loss: 0.4122 - accuracy: 0.8089 - val_loss: 0.4731 - val_accuracy: 0.7726 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "155/162 [===========================>..] - ETA: 0s - loss: 0.4041 - accuracy: 0.8119\n",
      "Epoch 15: val_accuracy did not improve from 0.77881\n",
      "162/162 [==============================] - 2s 12ms/step - loss: 0.4031 - accuracy: 0.8114 - val_loss: 0.4809 - val_accuracy: 0.7780 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "157/162 [============================>.] - ETA: 0s - loss: 0.3971 - accuracy: 0.8195\n",
      "Epoch 16: val_accuracy did not improve from 0.77881\n",
      "162/162 [==============================] - 2s 10ms/step - loss: 0.3979 - accuracy: 0.8190 - val_loss: 0.4788 - val_accuracy: 0.7780 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "154/162 [===========================>..] - ETA: 0s - loss: 0.3935 - accuracy: 0.8180\n",
      "Epoch 17: val_accuracy did not improve from 0.77881\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.3914 - accuracy: 0.8195 - val_loss: 0.4833 - val_accuracy: 0.7657 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "151/162 [==========================>...] - ETA: 0s - loss: 0.3905 - accuracy: 0.8166\n",
      "Epoch 18: val_accuracy did not improve from 0.77881\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.3874 - accuracy: 0.8188 - val_loss: 0.4858 - val_accuracy: 0.7726 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "160/162 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8285\n",
      "Epoch 19: val_accuracy did not improve from 0.77881\n",
      "\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "162/162 [==============================] - 2s 10ms/step - loss: 0.3826 - accuracy: 0.8279 - val_loss: 0.4916 - val_accuracy: 0.7788 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "151/162 [==========================>...] - ETA: 0s - loss: 0.3558 - accuracy: 0.8409\n",
      "Epoch 20: val_accuracy improved from 0.77881 to 0.78345, saving model to checkpoints\\model-20-0.78.hdf5\n",
      "162/162 [==============================] - 2s 11ms/step - loss: 0.3564 - accuracy: 0.8398 - val_loss: 0.4838 - val_accuracy: 0.7834 - lr: 1.0000e-04\n",
      "Epoch 21/1000\n",
      "154/162 [===========================>..] - ETA: 0s - loss: 0.3496 - accuracy: 0.8460\n",
      "Epoch 21: val_accuracy improved from 0.78345 to 0.78500, saving model to checkpoints\\model-21-0.78.hdf5\n",
      "162/162 [==============================] - 2s 10ms/step - loss: 0.3488 - accuracy: 0.8460 - val_loss: 0.4785 - val_accuracy: 0.7850 - lr: 1.0000e-04\n",
      "Epoch 22/1000\n",
      "153/162 [===========================>..] - ETA: 0s - loss: 0.3481 - accuracy: 0.8466\n",
      "Epoch 22: val_accuracy did not improve from 0.78500\n",
      "162/162 [==============================] - 2s 10ms/step - loss: 0.3462 - accuracy: 0.8470 - val_loss: 0.4814 - val_accuracy: 0.7780 - lr: 1.0000e-04\n",
      "Epoch 23/1000\n",
      "161/162 [============================>.] - ETA: 0s - loss: 0.3451 - accuracy: 0.8461\n",
      "Epoch 23: val_accuracy did not improve from 0.78500\n",
      "162/162 [==============================] - 1s 9ms/step - loss: 0.3444 - accuracy: 0.8466 - val_loss: 0.4806 - val_accuracy: 0.7811 - lr: 1.0000e-04\n",
      "Epoch 24/1000\n",
      "158/162 [============================>.] - ETA: 0s - loss: 0.3427 - accuracy: 0.8485\n",
      "Epoch 24: val_accuracy did not improve from 0.78500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.3431 - accuracy: 0.8482 - val_loss: 0.4826 - val_accuracy: 0.7811 - lr: 1.0000e-04\n",
      "Epoch 25/1000\n",
      "151/162 [==========================>...] - ETA: 0s - loss: 0.3424 - accuracy: 0.8498\n",
      "Epoch 25: val_accuracy did not improve from 0.78500\n",
      "162/162 [==============================] - 2s 11ms/step - loss: 0.3417 - accuracy: 0.8495 - val_loss: 0.4826 - val_accuracy: 0.7819 - lr: 1.0000e-04\n",
      "Epoch 26/1000\n",
      "150/162 [==========================>...] - ETA: 0s - loss: 0.3410 - accuracy: 0.8506\n",
      "Epoch 26: val_accuracy did not improve from 0.78500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.3406 - accuracy: 0.8515 - val_loss: 0.4888 - val_accuracy: 0.7780 - lr: 1.0000e-04\n",
      "Epoch 27/1000\n",
      "146/162 [==========================>...] - ETA: 0s - loss: 0.3409 - accuracy: 0.8497\n",
      "Epoch 27: val_accuracy did not improve from 0.78500\n",
      "162/162 [==============================] - 2s 10ms/step - loss: 0.3403 - accuracy: 0.8511 - val_loss: 0.4841 - val_accuracy: 0.7850 - lr: 1.0000e-04\n",
      "Epoch 28/1000\n",
      "152/162 [===========================>..] - ETA: 0s - loss: 0.3400 - accuracy: 0.8516\n",
      "Epoch 28: val_accuracy improved from 0.78500 to 0.78654, saving model to checkpoints\\model-28-0.79.hdf5\n",
      "162/162 [==============================] - 1s 8ms/step - loss: 0.3387 - accuracy: 0.8528 - val_loss: 0.4862 - val_accuracy: 0.7865 - lr: 1.0000e-04\n",
      "Epoch 29/1000\n",
      "150/162 [==========================>...] - ETA: 0s - loss: 0.3383 - accuracy: 0.8515\n",
      "Epoch 29: val_accuracy did not improve from 0.78654\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "162/162 [==============================] - 1s 8ms/step - loss: 0.3376 - accuracy: 0.8528 - val_loss: 0.4868 - val_accuracy: 0.7865 - lr: 1.0000e-04\n",
      "Epoch 30/1000\n",
      "162/162 [==============================] - ETA: 0s - loss: 0.3336 - accuracy: 0.8545\n",
      "Epoch 30: val_accuracy did not improve from 0.78654\n",
      "162/162 [==============================] - 1s 7ms/step - loss: 0.3336 - accuracy: 0.8545 - val_loss: 0.4871 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
      "Epoch 31/1000\n",
      "159/162 [============================>.] - ETA: 0s - loss: 0.3339 - accuracy: 0.8553\n",
      "Epoch 31: val_accuracy did not improve from 0.78654\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.3334 - accuracy: 0.8551 - val_loss: 0.4872 - val_accuracy: 0.7858 - lr: 1.0000e-05\n",
      "Epoch 32/1000\n",
      "150/162 [==========================>...] - ETA: 0s - loss: 0.3367 - accuracy: 0.8517\n",
      "Epoch 32: val_accuracy did not improve from 0.78654\n",
      "162/162 [==============================] - 2s 11ms/step - loss: 0.3333 - accuracy: 0.8549 - val_loss: 0.4872 - val_accuracy: 0.7850 - lr: 1.0000e-05\n",
      "Epoch 33/1000\n",
      "153/162 [===========================>..] - ETA: 0s - loss: 0.3329 - accuracy: 0.8558\n",
      "Epoch 33: val_accuracy did not improve from 0.78654\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.3332 - accuracy: 0.8557 - val_loss: 0.4872 - val_accuracy: 0.7850 - lr: 1.0000e-05\n",
      "Epoch 34/1000\n",
      "150/162 [==========================>...] - ETA: 0s - loss: 0.3283 - accuracy: 0.8602\n",
      "Epoch 34: val_accuracy did not improve from 0.78654\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.3330 - accuracy: 0.8563 - val_loss: 0.4874 - val_accuracy: 0.7850 - lr: 1.0000e-05\n",
      "Epoch 35/1000\n",
      "156/162 [===========================>..] - ETA: 0s - loss: 0.3320 - accuracy: 0.8564\n",
      "Epoch 35: val_accuracy did not improve from 0.78654\n",
      "162/162 [==============================] - 2s 11ms/step - loss: 0.3329 - accuracy: 0.8557 - val_loss: 0.4873 - val_accuracy: 0.7858 - lr: 1.0000e-05\n",
      "Epoch 36/1000\n",
      "159/162 [============================>.] - ETA: 0s - loss: 0.3331 - accuracy: 0.8550\n",
      "Epoch 36: val_accuracy did not improve from 0.78654\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.3328 - accuracy: 0.8553 - val_loss: 0.4875 - val_accuracy: 0.7858 - lr: 1.0000e-05\n",
      "Epoch 37/1000\n",
      "152/162 [===========================>..] - ETA: 0s - loss: 0.3341 - accuracy: 0.8544\n",
      "Epoch 37: val_accuracy did not improve from 0.78654\n",
      "162/162 [==============================] - 1s 9ms/step - loss: 0.3326 - accuracy: 0.8565 - val_loss: 0.4876 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
      "Epoch 38/1000\n",
      "156/162 [===========================>..] - ETA: 0s - loss: 0.3321 - accuracy: 0.8570\n",
      "Epoch 38: val_accuracy did not improve from 0.78654\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.3325 - accuracy: 0.8563 - val_loss: 0.4875 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
      "Epoch 38: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.binary_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy')]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled, \n",
    "    y_train, \n",
    "    epochs=1000,\n",
    "    validation_data=(X_test_scaled, y_test),\n",
    "    callbacks=[cb_checkpoint, cb_reducelr, cb_earlystop, cb_csvlogger]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ea578c-ef61-44eb-a243-e4f5092a2e20",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Final evaluation\n",
    "- You can now load the best model - it will be the one with the highest epoch number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "970d3a38-1915-457f-b9bb-e683aa4782d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tf.keras.models.load_model('checkpoints/model-25-0.80.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d946ea80-32c5-4a0d-9ab9-195461f77167",
   "metadata": {},
   "source": [
    "- Save yourself some time by calling `predict_classes()` instead of `predict()`\n",
    "- It assigns the classes automatically - you don't have to calculate them from probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e1d1c69-33ef-4749-b3c8-6ede188a1f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 1, 0, 1], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_preds = np.ravel(best_model.predict_classes(X_test_scaled))\n",
    "best_model_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6d6581-8b03-4e7b-b591-dd9444d6a3b1",
   "metadata": {},
   "source": [
    "- Evaluate as you normally would"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30bacbff-f634-43af-b79c-171559aca9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7981438515081206\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_test, best_model_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
